#Python code for accessing Twitter API

pip install tweepy --upgrade

import tweepy
import pandas as pd

from datetime import date, datetime, timedelta

import time

import re

import nltk
nltk.download('vader_lexicon')

from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA


#Config Academic access, limited to 10 million tweets per month
BEARER_TOKEN = 'AAAAAAAAAAAAAAAAAAAAAHNhigEAAAAAwHSUHVAVIybNuWMQpwnL0ZLPL%2B0%3DpVmEp29k7ROb1Sq8m8Q9LtX4JS2Sna70X8AHCqR3NxzIni1pkL'
consumer_api_key = 'Gb3xYTwp17nWvY358lxBiAR30'
consumer_api_secret = 'QtOldDkAWAZ1GLCuyhllnBShJyFM0jpQPgmrqMt441SQ8BGrMh'



#Collecting tweets (don't think the code is working now, was improving it but didn't had the time to finish it)
client = tweepy.Client(bearer_token=BEARER_TOKEN)

#Input
query= '(btc OR Bitcoin OR #btc OR #Bitcoin) lang: en -is:retweet'

start_date = '2013-01-01T00:00:00Z'
end_date = '2013-01-01T23:59:59Z'

data = []
n = 1
day_count = 2

#Moving day by day
for single_date in (datetime.strptime(end_date,"%Y-%m-%dT%H:%M:%SZ") + timedelta(days=n) for n in range(day_count)):
  single_date = single_date.strftime("%Y-%m-%dT%H:%M:%SZ")
 
#Search Tweets 
  response = client.search_all_tweets(query = query, max_results=500, start_time=start_date, end_time=single_date, tweet_fields=['created_at','public_metrics'])
  time.sleep(5)
    

#Add tweets (per day) in list called Data
  for tweet in response.data:
    data.append([tweet.created_at, tweet.text, tweet.public_metrics])


#Putting data into data frame
df = pd.DataFrame(data, columns = ['Time', 'Tweet', 'Metrics'])
print(df)

#Data to CSV
df.to_csv('tweetsTestV1.csv')



#VADER sentiment analysis

#Loading the file and printing first 3 rows for comparison
f_data = pd.read_excel('/content/tweetsTestV2 xlsx (1).xlsx')

f_data.head(3)

#Remove twitter handlers
f_data.Tweet = f_data.Tweet.apply(lambda x:re.sub('@[^\s]+','',x))

#Remove hashtags
f_data.Tweet = f_data.Tweet.apply(lambda x:re.sub(r'\B#\S+','',x))

#Remove Dollar Signs
f_data.Tweet = f_data.Tweet.apply(lambda x:re.sub(r'\$\S+','',x))

# Remove URLS
f_data.Tweet = f_data.Tweet.apply(lambda x:re.sub(r"http\S+", "", x))

# Remove all the special characters #Even kijken of dit moet, dan gaan de emojis ook weg nml
f_data.Tweet = f_data.Tweet.apply(lambda x:' '.join(re.findall(r'\w+', x)))

# Substituting multiple spaces with single space
f_data.Tweet = f_data.Tweet.apply(lambda x:re.sub(r'\s+', ' ', x, flags=re.I))

sid = SIA()
f_data['sentiments']           = f_data['Tweet'].apply(lambda x: sid.polarity_scores(' '.join(re.findall(r'\w+',x.lower()))))
f_data['Positive Sentiment']   = f_data['sentiments'].apply(lambda x: x['pos']+1*(10**-6)) 
f_data['Neutral Sentiment']    = f_data['sentiments'].apply(lambda x: x['neu']+1*(10**-6))
f_data['Negative Sentiment']   = f_data['sentiments'].apply(lambda x: x['neg']+1*(10**-6))

f_data.drop(columns=['sentiments'],inplace=True)

f_data.head(100)

